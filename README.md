# Catho Job Scraper

Este projeto Ã© um web scraper desenvolvido para extrair informaÃ§Ãµes de vagas de emprego no site Catho, utilizando Selenium e BeautifulSoup. O usuÃ¡rio pode realizar buscas personalizadas de vagas por palavra-chave, e os dados extraÃ­dos, como tÃ­tulo, empresa, salÃ¡rio, localizaÃ§Ã£o e data de publicaÃ§Ã£o, sÃ£o armazenados em um banco de dados SQLite.

## âš™ï¸ Funcionalidades

- ğŸ” **Busca automatizada de vagas** por palavra-chave no site da Catho.
- ğŸ“ **ExtraÃ§Ã£o de informaÃ§Ãµes das vagas**, incluindo:
  - **TÃ­tulo da vaga**
  - **Nome da empresa**
  - **SalÃ¡rio**
  - **LocalizaÃ§Ã£o**
  - **Data de publicaÃ§Ã£o**
- ğŸ—„ï¸ **Armazenamento dinÃ¢mico**: As vagas sÃ£o salvas em uma tabela SQLite, cujo nome Ã© gerado automaticamente com base no termo de pesquisa fornecido pelo usuÃ¡rio.
- ğŸš« **Bypass automÃ¡tico de anÃºncios** e pop-ups que aparecem durante o carregamento do site.
- âŒ¨ï¸ Uso de teclas (Enter) para simular a pesquisa diretamente no campo de busca.

## ğŸ› ï¸ PrÃ©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas em sua mÃ¡quina:

- [Python 3.x](https://www.python.org/downloads/)
- [Selenium](https://www.selenium.dev/)
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [SQLite3](https://www.sqlite.org/index.html) (para o banco de dados)
- [Geckodriver](https://github.com/mozilla/geckodriver/releases) (para rodar com o Firefox)

Instale as dependÃªncias necessÃ¡rias executando:

```bash
pip install selenium beautifulsoup4 sqlite3


Instale as dependÃªncias necessÃ¡rias executando:

```bash
pip install selenium beautifulsoup4


ğŸš€ ConfiguraÃ§Ã£o
Clone este repositÃ³rio:

bash
Copiar cÃ³digo
git clone https://github.com/seu-usuario/catho-job-scraper.git
cd catho-job-scraper
Baixe e configure o Geckodriver e adicione-o ao seu PATH, ou indique o caminho no script.

Execute o script:

bash
Copiar cÃ³digo
python web.py
ApÃ³s rodar o script, vocÃª serÃ¡ solicitado a digitar o cargo ou palavra-chave para buscar as vagas.

ğŸ“‚ Estrutura do CÃ³digo
web.py: Script principal que executa a automaÃ§Ã£o do navegador, faz a busca da vaga, extrai os dados e exibe no console.
vagas.db: Arquivo de banco de dados SQLite que serÃ¡ criado automaticamente para armazenar as vagas extraÃ­das.

ğŸ”§ PersonalizaÃ§Ã£o
VocÃª pode ajustar a busca para filtrar vagas por diferentes critÃ©rios, como localizaÃ§Ã£o, tipo de contrato, entre outros, ajustando o campo de pesquisa e os seletores de CSS no script.

Os dados sÃ£o armazenados em um banco de dados SQLite com uma tabela cujo nome Ã© gerado dinamicamente no formato:

Exemplo: Se o usuÃ¡rio buscar por "Desenvolvedor Python", a tabela serÃ¡ criada como vagas_de_desenvolvedor_python.

As colunas da tabela incluem:

id: Identificador Ãºnico da vaga (chave primÃ¡ria).
titulo: TÃ­tulo da vaga.
empresa: Nome da empresa.
salario: SalÃ¡rio oferecido (se disponÃ­vel).
localizacao: LocalizaÃ§Ã£o da vaga.
data_publicacao: Data de publicaÃ§Ã£o ou atualizaÃ§Ã£o da vaga.

ğŸ› ï¸ Futuras ImplementaÃ§Ãµes
Melhor tratamento de exceÃ§Ãµes.
ExportaÃ§Ã£o dos dados extraÃ­dos para um arquivo CSV ou JSON.
Suporte a diferentes navegadores alÃ©m do Firefox.

ğŸ¤ ContribuiÃ§Ã£o
Sinta-se Ã  vontade para contribuir com este projeto. Para isso, faÃ§a um fork, crie uma branch, faÃ§a suas alteraÃ§Ãµes e envie um pull request.
